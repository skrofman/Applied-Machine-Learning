{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA_310_Lecture_39_Spring_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skrofman/Applied-Machine-Learning/blob/master/DATA_310_Lecture_39_Spring_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsv8GUYM6qR1"
      },
      "source": [
        "# DATA 310 - Lecture 39"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47zhKygt16DR"
      },
      "source": [
        "##<font color='darkgreen' face='Papyrus' size=12pt>Natural Language Processing (part II)</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeSccFn3kPfE"
      },
      "source": [
        "<font color='crimson'>**Objective:** use speech and words along with computer run algorithms.\n",
        "\n",
        "<span style=\"font-family:Calibri; color:darkblue; font-size:18pt;\">Examples of projects/research with NLP:</span>\n",
        "\n",
        "<font color='blue'>*Sentiment Analysis*</font> - How positive or negative is text about a topic? \n",
        "\n",
        "<font color='blue'>*Prediction*</font> - What genres should Netflix classify a movie as to maximize views? Based on product reviews, can we predict the star rating of a product?\n",
        "\n",
        "<font color='blue'>*Translation*</font> - Recognize words in one language to provide similar words in another.\n",
        "\n",
        "**Playground:** https://www.deepl.com/translator\n",
        "\n",
        "\n",
        "<font color='blue'>*Summarization*</font> - Take a long document and produce a shorter one (a synthesis) without losing meaningful information.\n",
        "\n",
        "\n",
        "<font color='forestgreen'>**Methods:**</font> <span style=\"font-family:Calibri; color:red; font-size:12pt;\">The main idea is to quantify the occurrence of relevant words and, based on the context, to map them into vectors. That is to say that we want to create mathematically representable quantities from words and text; they will serve as features for data analysis. One approach is separate the text data into sentences and then sentences can be used to extract (key) words and expressions.</span>\n",
        "\n",
        "###**Regular Expressions (regex)**\n",
        "\n",
        "Goal: provide a language that allows us to search for different text strings.\n",
        "\n",
        "For example, Regular Expressions (frequently called “regex”) allows us to label all tweets with a “1” if they contain the following list of words:\n",
        "\n",
        "- college\n",
        "- College of\n",
        "- colleges\n",
        "- The College\n",
        "\n",
        "The idea is to detect that in all expressions above we have the same concept \"college\".\n",
        "\n",
        "\n",
        "\n",
        "<font color='blue' face='Calibri' size=5pt>Examples of common REGEX patterns</font>\n",
        "\n",
        "**[tT]**imber  - would match lower or uppercase T\n",
        "\n",
        "**[A-Z]** - would match any capital character\n",
        "\n",
        "**[a-z]** - would match any lowercase character\n",
        "\n",
        "**[0-9]** - would match any single number (i.e., 9)\n",
        "\n",
        "**[^A-Z]** - would match anything that isn’t an uppercase letter.\n",
        "\n",
        "**\\w** - would match any letter.\n",
        "\n",
        "A comprehensive manual on regex can be found here:\n",
        "https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjXxyULYjYT9"
      },
      "source": [
        "# import regex in Python\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XnTsc2O60Ol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c255e77-a9b8-4902-d0ee-dd7373ae46c1"
      },
      "source": [
        "pattern = r\"\\weliciou\"\n",
        "sequence = \"Chocolate is not delicious\"\n",
        "sequence2 = \"This new recipe deliciously implemented a new idea about the texture of the chocolate.\"\n",
        "if re.search(pattern, sequence):\n",
        "  print(\"Match!\")\n",
        "else: print(\"Not a match!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BaUHIou70ez"
      },
      "source": [
        "###An example for replacing the spaces between words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKtrHwsD65vM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "48b3b600-1d9f-4fc2-8cf9-0e393a61bef5"
      },
      "source": [
        "text = \"This chocolate is delicious but it may have too many calories, such as 400.\"\n",
        "re.sub('[^a-zA-Z0-9]','_',text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'This_chocolate_is_delicious_but_it_may_have_too_many_calories__such_as_400_'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dk4zqK08L7y"
      },
      "source": [
        "###An example for matching a patttern (a sequence of characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL91n3Zy7x08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe559ab-07cd-48b4-de9b-d68420d10c52"
      },
      "source": [
        "pattern = r\"[cC]hoco\"\n",
        "sequence = \"Chocolate is delicious\"\n",
        "if re.match(pattern, sequence):\n",
        "  print(\"Match!\")\n",
        "else: print(\"Not a match!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxp0kAGuMc2y"
      },
      "source": [
        "### Rooting words is very important ! (in short, an identifier of the meaning of the word)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAp3N5p88Wwc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddf48ff-df86-4168-c686-577b7fd796ac"
      },
      "source": [
        "pattern = r\"good for you\"\n",
        "sentence = \"Chocolate is delicious and good for you\"\n",
        "if re.search(pattern, sentence):\n",
        "  print(\"Match!\")\n",
        "else: print(\"Not a match!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeXHM2fn9zil"
      },
      "source": [
        "###Example:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1AMHbSgq3MHcv8Q8ljnHvl5IkxTKkzGkx' \n",
        "width='600px' />\n",
        "<figcaption>Data from Twitter</figcaption></center>\n",
        "</figure>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr1AOY-18eRD"
      },
      "source": [
        "text = \"\"\"Rep. Stephanie Murphy Verified account @RepStephMurphy Aug 30 More Celebrating 100yrs of coeducation at @williamandmary, \n",
        "        it was a true honor to return to my alma mater & join its first female president, Katherine Rowe, to welcome students at their convocation. \n",
        "        I spoke about the power of patriotism & the urgent need for active, engaged citizens.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51YBSini_hUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c030051-5996-4dd9-a45a-ddc8419cb533"
      },
      "source": [
        "pattern = r\"[cC]elebrating\"\n",
        "if re.search(pattern, text):\n",
        "  print(\"Match!\")\n",
        "else: print(\"Not a match!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfxPZBsd_mXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3014188-5867-4763-c4de-8f3d8a6d56ed"
      },
      "source": [
        "pattern = r\"\\welebrat[a-z]+\"\n",
        "if re.search(pattern, text):\n",
        "  print(\"Match!\")\n",
        "else: print(\"Not a match!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WE1A7C8AeVy"
      },
      "source": [
        "<font face='Calibri' color='blue' size=5pt>The Bag of Words model (BoW)</font>\n",
        "\n",
        "**Main Goal:** use concurrences within context and counts of keywords to make predictions.\n",
        "\n",
        "**Observation:** there are many words that do not matter (such as prepositions or definite and indefinite articles). \n",
        "\n",
        "**Important:** each word can be translated into a binary value of occurrence.\n",
        "\n",
        "<span style=\"font-family:Calibri; color:darkblue; font-size:5pt;\">Analog Example:</span>\n",
        "\n",
        "*Statement 1*: Jurassic World was the pinnacle of human achievement.\n",
        "\n",
        "*Statement 2*: Human kind would be better without Jurassic World.\n",
        "\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1EUGNgop58BOOhFGHR3iKs5gXbrji6jEM' \n",
        "width='600px' />\n",
        "<figcaption>What is the difference in the statements above?</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "**Method**: we discard the *stopwords* such as articles, prepositions, verbs and retain the *corpus* (important words or *roots* of important words).\n",
        "\n",
        "\n",
        "\n",
        "A simple model based on this data:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1-uuXfXiYlmub8DauhxhYYCP2TKqfdvoB' \n",
        "width='600px' />\n",
        "<figcaption>The differences can be highlighted by using a count/vectorizer method</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "**Main idea:** analyze differences and co-occurrencies.\n",
        "\n",
        "**Known Problems:**\n",
        "\n",
        " - If some sentences are much longer in length, the vocabulary would increase and as such, the length of the vectors would increase; this is a dimensionality problem.\n",
        " - The new sentences may contain more different words from the previous sentences.\n",
        " - The vectors would also contain many zeros, thereby resulting in a sparse matrix.\n",
        " - No information on the grammatical structure or the actual ordering of the words is being used.\n",
        "\n",
        "**Possible Solution:** Term Frequency-Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "The term frequency-inverse document frequency is a measure that quantifies the importance of a word in the context of a document or a *corpus*.\n",
        "\n",
        "The *term-frequency* of a word is the relative frequency of the term in the context of the document.\n",
        "\n",
        "$$\\text{TF}(t,d):=\\frac{\\text{# of times the term appears in the document}}{\\text{# of terms in the document }}$$\n",
        "\n",
        "\n",
        "The *inverse document frequency* is defined as:\n",
        "\n",
        "$$\\text{IDF}(t,d):=\\log\\left(\\frac{\\text{# of documents}}{\\text{# of documents with term } t}\\right)$$\n",
        "\n",
        "Our quantification of relative importance is defined as the product between TF and IDF.\n",
        "\n",
        "TF-IDF gives larger values for less frequent words and is high when both IDF and TF values are high, for instance the word is rare in all the documents combined but frequent in a single document.\n",
        "\n",
        "A good Python example can be found here: \n",
        "\n",
        "https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-rVM7uOAFj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf1ff7e-d516-4b01-e56f-85804bf83b05"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcgT03h3BW-t"
      },
      "source": [
        "text = open(\"drive/MyDrive/Data Sets/Christmas_Carol.txt\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmmUvIi4YTSy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "b449688b-f4e2-4cb0-9ffd-8dfddcbc0899"
      },
      "source": [
        "text[1:1000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" CHRISTMAS CAROL\\n\\nIN PROSE\\nBEING\\nA Ghost Story of Christmas\\n\\nby Charles Dickens\\n\\n\\n\\nPREFACE\\n\\nI HAVE endeavoured in this Ghostly little book,\\nto raise the Ghost of an Idea, which shall not put my\\nreaders out of humour with themselves, with each other,\\nwith the season, or with me.  May it haunt their houses\\npleasantly, and no one wish to lay it.\\n\\nTheir faithful Friend and Servant,\\n                                   C. D.\\nDecember, 1843.\\n\\n\\n\\nCONTENTS\\n\\nStave   I: Marley's Ghost\\nStave  II: The First of the Three Spirits\\nStave III: The Second of the Three Spirits\\nStave  IV: The Last of the Spirits\\nStave   V: The End of It\\n\\n\\n\\nSTAVE I:  MARLEY'S GHOST\\n\\nMARLEY was dead: to begin with. There is no doubt\\nwhatever about that. The register of his burial was\\nsigned by the clergyman, the clerk, the undertaker,\\nand the chief mourner. Scrooge signed it: and\\nScrooge's name was good upon 'Change, for anything he\\nchose to put his hand to. Old Marley was as dead as a\\ndoor-nail.\\n\\nMind! I don't mean to say th\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwPgD4RsBeVS"
      },
      "source": [
        "<font face=\"Calibri\" color='navy' size=4pt>We can extract all the sentences (based on punctuation):</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PobVsJyzB9mJ"
      },
      "source": [
        "dataset = nltk.sent_tokenize(text) \n",
        "for i in range(len(dataset)): \n",
        "    dataset[i] = dataset[i].lower() \n",
        "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) \n",
        "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIAkuuEdCEZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f69570e4-cac8-4c8a-e565-ce2a3c9f1836"
      },
      "source": [
        "# this is the 1900th sentence\n",
        "dataset[1899]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'so did the plump sister when she came '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VbuMt_-3gNt"
      },
      "source": [
        "What do you notice? There are no capital letters, no punctuation (because the computer does not need them).\n",
        "\n",
        "We can also determine how frequent are the different words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liv9PCWGCOp7"
      },
      "source": [
        "# we can count the occurrencies of different words\n",
        "# Creating the Bag of Words model \n",
        "word2count = {} \n",
        "for data in dataset: \n",
        "    words = nltk.word_tokenize(data) \n",
        "    for word in words: \n",
        "        if word not in word2count.keys(): \n",
        "            word2count[word] = 1\n",
        "        else: \n",
        "            word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdglAkPpCZp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21e10e7-a2cd-4020-c69d-cda1f07a1d6f"
      },
      "source": [
        "word2count.get('wealth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpgPnOqmDOzp"
      },
      "source": [
        "This means that the word \"ghost\" appeared 95 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icqKTzLnCaZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d86bed-b0ae-4d95-c50e-45bc826a9906"
      },
      "source": [
        "word2count.get('scrooge')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a81WOQYhDQn5"
      },
      "source": [
        "<font face=\"Calibri\" color='navy' size=4pt>We can determine what are the most frequent words, for example:</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT3CP1V4DhxL"
      },
      "source": [
        "# the top 100 most frequent words\n",
        "import heapq \n",
        "freq_words = heapq.nlargest(100, word2count, key=word2count.get)\n",
        "freq_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldxUtPD_EIZs"
      },
      "source": [
        "Indeed this is a story about \"Scrooge\" and \"ghosts\"...\n",
        "\n",
        "Important: we want to discard all the unimportant words (as known as \"stopwords\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnDYV22LEAKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20280244-bdf3-45c2-98a4-d424047575cb"
      },
      "source": [
        "# Stopword dictionary\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "# For stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cv4uf8jEmfY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2cbda07-c18a-4fcd-b7f4-eb97a1c41e06"
      },
      "source": [
        "txt = re.sub('[^a-zA-Z0-9 ]','',dataset[0])\n",
        "# Make everything lower case\n",
        "txt = txt.lower()\n",
        "# Make it a list of words\n",
        "txt = txt.split()\n",
        "# Get all the stop words out\n",
        "txt = [word for word in txt if not word in set(stopwords.words('english'))]\n",
        "# Stem the words\n",
        "txt = [stemmer.stem(word) for word in txt]\n",
        "# Put it all back together and look at the result\n",
        "' '.join(txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'christma carol prose ghost stori christma charl dicken prefac endeavour ghostli littl book rais ghost idea shall put reader humour season'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cShN8rfsEyL5"
      },
      "source": [
        "..and we want to do this for every sentence in the book:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZkkVIhVExLH"
      },
      "source": [
        "corpus = []\n",
        "for i in range(len(dataset)):\n",
        "    txt = re.sub('[^a-zA-Z0-9 ]','',dataset[i])\n",
        "    txt = txt.lower()\n",
        "    txt = txt.split()\n",
        "    txt = [word for word in txt if not word in set(stopwords.words('english'))]\n",
        "    txt = [stemmer.stem(word) for word in txt]\n",
        "    txt = ' '.join(txt)\n",
        "    corpus.append(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n2VU3JwE4DL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611cbe96-2c4b-4c61-8f16-5805ef290969"
      },
      "source": [
        "corpus[100:120]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clerk tank involuntarili applaud',\n",
              " 'becom immedi sensibl improprieti poke fire extinguish last frail spark ever',\n",
              " 'let hear anoth sound said scroog keep christma lose situat',\n",
              " 'quit power speaker sir ad turn nephew',\n",
              " 'wonder go parliament',\n",
              " 'angri uncl',\n",
              " 'come',\n",
              " 'dine us morrow',\n",
              " 'scroog said would see ye inde',\n",
              " 'went whole length express said would see extrem first',\n",
              " '',\n",
              " 'cri scroog nephew',\n",
              " '',\n",
              " 'get marri',\n",
              " 'said scroog',\n",
              " 'fell love',\n",
              " 'fell love',\n",
              " 'growl scroog one thing world ridicul merri christma',\n",
              " 'good afternoon',\n",
              " 'nay uncl never came see happen']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGZOJeHKFA7r"
      },
      "source": [
        "# we can count the occurrencies of different words in the corpus\n",
        "# Creating the Bag of Words model \n",
        "word2count = {} \n",
        "for data in corpus: \n",
        "    words = nltk.word_tokenize(data) \n",
        "    for word in words: \n",
        "        if word not in word2count.keys(): \n",
        "            word2count[word] = 1\n",
        "        else: \n",
        "            word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbheF3ELFGyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80507504-8ed9-4f66-9d44-c6fe4fddf1be"
      },
      "source": [
        "# .. and get the top 10 most frequent in the corpus:\n",
        "freq_words = heapq.nlargest(20, word2count, key=word2count.get)\n",
        "freq_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scroog',\n",
              " 'said',\n",
              " 'upon',\n",
              " 'one',\n",
              " 'spirit',\n",
              " 'ghost',\n",
              " 'christma',\n",
              " 'would',\n",
              " 'hand',\n",
              " 'man',\n",
              " 'look',\n",
              " 'time',\n",
              " 'like',\n",
              " 'old',\n",
              " 'know',\n",
              " 'good',\n",
              " 'littl',\n",
              " 'could',\n",
              " 'cri',\n",
              " 'come']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-NGVIDzFL4J"
      },
      "source": [
        "## Application to Amazon customer reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeNYrf-JcNp_"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soXF4QCQFOtz"
      },
      "source": [
        "df = pd.read_csv('7817_1.csv', quoting=2 )\n",
        "# Extract the ratings and text reviews\n",
        "data = df[['reviews.text', 'reviews.rating']].dropna().reset_index(drop=True)\n",
        "\n",
        "reviews = data['reviews.text']\n",
        "y = data['reviews.rating']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n92B5NCDcSRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "497cb079-ccad-4364-d443-00bebbd23039"
      },
      "source": [
        "data.loc[2,'reviews.text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I am enjoying it so far. Great for reading. Had the original Fire since 2012. The Fire used to make my eyes hurt if I read too long. Haven't experienced that with the Paperwhite yet.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDhklObNFb-V"
      },
      "source": [
        "To learn more about the data:   \n",
        "\n",
        "https://www.kaggle.com/bittlingmayer/amazonreviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_7DersbFcfR"
      },
      "source": [
        "corpus = []\n",
        "for i in range(len(reviews)):\n",
        "    txt = re.sub('[^a-zA-Z0-9 ]','',reviews[i])\n",
        "    txt = txt.lower()\n",
        "    txt = txt.split()\n",
        "    txt = [word for word in txt if not word in set(stopwords.words('english'))]\n",
        "    txt = [stemmer.stem(word) for word in txt]\n",
        "    txt = ' '.join(txt)\n",
        "    corpus.append(txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRgcjbYWIRRP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e222d634-210c-45a4-d9d7-0b5577511ad7"
      },
      "source": [
        "corpus[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'initi troubl decid paperwhit voyag review less said thing paperwhit great spend money go voyagefortun friend own end buy paperwhit basi model 300 ppi 80 dollar jump turn pricey voyag page press isnt alway sensit fine specif set dont need auto light adjustmentit week love paperwhit regret touch screen recept easi use keep light specif set regardless time day case hard chang set either youll chang light level certain time day everi readingalso glad went intern ship option amazon extra expens deliveri time track didnt need worri custom may use third parti ship servic'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWb4ZixhFpQ1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "X_raw = cv.fit_transform(corpus)\n",
        "X = X_raw.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXibZEqWdPPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f47938-6b14-4e1a-88a5-350802fa4f66"
      },
      "source": [
        "X[0,:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukfkEpSMFuie"
      },
      "source": [
        "yb = y.where(y==5, other=0).where(y<5, other=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqSbY30WIx1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5525949-53fe-4b21-d7de-6d6fcc4419e2"
      },
      "source": [
        "yb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1.0\n",
              "1       1.0\n",
              "2       0.0\n",
              "3       1.0\n",
              "4       1.0\n",
              "       ... \n",
              "1172    0.0\n",
              "1173    0.0\n",
              "1174    0.0\n",
              "1175    0.0\n",
              "1176    0.0\n",
              "Name: reviews.rating, Length: 1177, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Do_3AbH9IG"
      },
      "source": [
        "### Logistic Regression Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSBtBGAbF9Uj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "63653f8e-e4ea-4547-be6c-7e6f493898a3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,yb,random_state=1234,test_size=0.25)\n",
        "cls = LogisticRegression(random_state=1234, solver='lbfgs')\n",
        "cls.fit(Xtrain,ytrain)\n",
        "ypred = cls.predict(Xtest)\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Not 5</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Not 5</th>\n",
              "      <td>56</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30</td>\n",
              "      <td>159</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Not 5    5\n",
              "Not 5     56   50\n",
              "5         30  159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIO4S8lWJjdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3ecc22-50d8-4104-def1-9a55ce574973"
      },
      "source": [
        "acc(ytest,ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7288135593220338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNNCmCZwH_ky"
      },
      "source": [
        "### Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR17RiZMHkHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a2540f0f-465a-4a46-d1db-b7a188560aa5"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "cls = GaussianNB()\n",
        "cls.fit(Xtrain,ytrain)\n",
        "ypred = cls.predict(Xtest)\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Not 5</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Not 5</th>\n",
              "      <td>72</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>76</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Not 5    5\n",
              "Not 5     72   34\n",
              "5         76  113"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy4_0A11eZ6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c97b1c4-5b7c-4de5-ab7b-bdc53950bfea"
      },
      "source": [
        "acc(ytest,ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6271186440677966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pea2T1NnIEC7"
      },
      "source": [
        "### Random Forest Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9dpA18ZF6HZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "f3af6da1-6ae3-4b6b-fbb1-6a6941f95332"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "Xtrain,Xtest,ytrain,ytest = tts(X,yb,random_state=1234,test_size=0.25)\n",
        "cls = RandomForestClassifier(random_state=1234, max_depth=100, n_estimators = 100)\n",
        "cls.fit(Xtrain,ytrain)\n",
        "ypred = cls.predict(Xtest)\n",
        "cm = confusion_matrix(ytest, ypred)\n",
        "pd.DataFrame(cm, columns=['Not 5', '5'], index =['Not 5', '5'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Not 5</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Not 5</th>\n",
              "      <td>47</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Not 5    5\n",
              "Not 5     47   59\n",
              "5         11  178"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va1QXBwpetaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ac3bbf-b231-4a52-f0ba-aff9f465691f"
      },
      "source": [
        "acc(ytest,ypred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7627118644067796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jGLmCiMI_sg"
      },
      "source": [
        "## Application to wine ratings based on customer reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUtoy0hQI_Io"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk import download\n",
        "download('stopwords')\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GckK-WM1JlgQ"
      },
      "source": [
        "%%time\n",
        "wine_data = pd.read_csv('winemagdata130kv2.csv',quoting=2)\n",
        "wines = wine_data[[\"description\",\"points\"]]\n",
        "wines_subset = wines.sample(1000,random_state=1693).reset_index(drop=True)\n",
        "corpus = []\n",
        "\n",
        "for i in range(0,len(wines_subset)):\n",
        "    wine_descriptions = re.sub('[^a-zA-Z0-9 ]','',wines_subset[\"description\"][i])\n",
        "    wine_descriptions=wine_descriptions.lower()\n",
        "    wine_descriptions = wine_descriptions.split()\n",
        "    wine_descriptions = [word for word in wine_descriptions if not word in set(stopwords.words('english'))]\n",
        "    stemmer = PorterStemmer()\n",
        "    wine_descriptions = [stemmer.stem(word) for word in wine_descriptions]\n",
        "    wine_descriptions = \" \".join(wine_descriptions)\n",
        "    corpus.append(wine_descriptions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSlRbCJpJ2uO"
      },
      "source": [
        "%%time\n",
        "countVec = CountVectorizer()\n",
        "X_raw = countVec.fit_transform(corpus)\n",
        "X = X_raw.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-0xqoC4J_X0"
      },
      "source": [
        "#### Visualize the distribution of the wine ratings (points)\n",
        "n, bins, patches = plt.hist(wines_subset[\"points\"].values,10,density=1,facecolor='green',alpha=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0ASsfjQKCro"
      },
      "source": [
        "y = wines_subset[\"points\"]\n",
        "y = y.where(y>90,other=0).where(y<=90,other=1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlkycIzvKID2"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = tts(X,y,test_size=0.25,random_state=1693)\n",
        "#scale_X = StandardScaler()\n",
        "#X_train = scale_X.fit_transform(X_train)\n",
        "#X_test = scale_X.transform(X_test)\n",
        "classifier = LogisticRegression(random_state=1693,solver='lbfgs')\n",
        "classifier.fit(X_train,Y_train)\n",
        "Y_pred = classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3FQUwCtKLdV"
      },
      "source": [
        "spc = ['Bad','Good']\n",
        "cm = confusion_matrix(Y_test,Y_pred)\n",
        "pd.DataFrame(cm, columns=spc, index=spc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkA8T6AltEMI"
      },
      "source": [
        "###<font color='blue'> Probabilistic Language Modeling \n",
        "\n",
        "**Goal:** Assign the probability that a sequence of words such as $(w_1,w_2,w_3,...w_n)$ occurs:\n",
        "\n",
        "$$\\mathcal{P}(\\text{Sentence})=\\mathcal{P}(w_1,w_2,w_3,...w_n)=\\mathcal{P}(w_1)*\\mathcal{P}(w_2,w_3,w_4...w_n|w_1)=$$\n",
        "\n",
        "Smartphones use this information to predict what the next word you will type will be, for example:\n",
        "\n",
        "$$\\mathcal{P}(w_1,w_2,w_3,w_4)=\\mathcal{P}(w_1)*\\mathcal{P}(w_4,w_3,w_2|w_1)=\\mathcal{P}(w_1)*\\mathcal{P}(w_2|w_1)*\\mathcal{P}(w_4,w_3|w_2,w_1)=\\mathcal{P}(w_1)*\\mathcal{P}(w_2|w_1)*\\mathcal{P}(w_3|w_1,w_2)*\\mathcal{P}(w_4|w_1,w_2,w_3)$$ \n",
        "\n",
        "which mean the probability of word $w_4$ provided the words $w_1, w_2$ and $w_3$ occurred.\n",
        "\n",
        "<font face='Calibri' color='blue' size=4pt>Critical thinking:</span> How do we compute these probability values?</font>\n",
        "\n",
        "<span style=\"font-family:Calibri; color:red; font-size:14pt;\">Reasoning:</span> We compute the frequency of occurrence for different sequences of words.\n",
        "\n",
        "\n",
        "<span style=\"font-family:Calibri; color:darkgreen; font-size:12pt;\"> P(today | It, is, sunny) = 50%\n",
        "The model you use to predict is called the “language model” </span>\n",
        "\n",
        "\n",
        "<span style=\"font-family:Calibri; color:purple; font-size:14pt;\"> Important Concept:</span> The Conditional Probability Rule states that probabilities of an events in the future are defined by the multiplication of all (conditional) probabilities leading to that given event.\n",
        "\n",
        "P(Today, it, was, sunny) = P(Today) * P(it | Today) * P(was | Today, it) * P(sunny | Today, it, was)\n",
        "\n",
        "P(Today, is, the, fiftennth) = P(Today) * P(is | Today) * P(the | Today, is) * P(fifteenth | Today, is, the)\n",
        "\n",
        "1. Unigram Models:\n",
        "        a. P(rainy | Today, it, was) ~ P(Today) * P(it) * P(was)\n",
        "2. Bigram Models:\n",
        "        a. P(rainy| Today, it, was) ~ P(rainy | was)\n",
        "3. N-gram models:\n",
        "        a. Same as the above, but for arbitrary distances.\n",
        "        b. For example a tri-gram: P(rainy | Today, it, was)\n",
        "            \n",
        "Often used in nested ways (i.e., a 3-gram model + unigram).\n",
        "\n",
        "\n",
        "### Evaluating NLP\n",
        "\n",
        "• The goal of any NLP activity is important in deciding how to evaluate it.\n",
        "\n",
        "• In a Bag of Words model, evaluation can come from classification accuracy (i.e., you have a training and test dataset).\n",
        "\n",
        "• But what if you’re writing an algorithm that predicts the next word for a texting app?\n",
        "\n",
        "### Perplexity an evaluative measure for NLP\n",
        "\n",
        "One might expect a model to be good at predicting cold in this sentence:\n",
        "\n",
        "“It is cold.”\n",
        "\n",
        "And not as good at predicting:\n",
        "\n",
        "“It is very cool outside when the winter is cold”\n",
        "\n",
        "For a variety of reasons; the biggest is the complexity/length of the sentence.\n",
        "\n",
        "• Perplexity is a measurement of how well a probability model predicts a test data. In the context of Natural Language Processing, perplexity is one way to evaluate language models.\n",
        "\n",
        "• Perplexity is an exponentiation of the entropy.\n",
        "\n",
        "• Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of an *entropy*.\n",
        "\n",
        "• The goal is to minimize Perplexity(W).\n",
        "\n",
        "Calculation of perplexity for a full a sequence of words: \n",
        "\n",
        "$$\\sqrt{\\prod_{i=1}^{n}\\frac{1}{P(w_i|w_{1}w_{2}...w_{i-1})}}$$\n",
        "\n",
        "Important applciations for Natural Language Processing:\n",
        "\t\n",
        "    • Sentiment Analysis\n",
        "\t\n",
        "    • Speech Recognition\n",
        "\t\n",
        "    • Information Retrieval\n",
        "\n",
        "    • Question Answering\n",
        "\n",
        "<span style=\"font-family:Calibri; color:blue; font-size:14pt;\">Big Idea:</span> Represent words as vectors: GloVe, Word2Vec algorithms (both are based on neural networks). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zvNZkDf-3re"
      },
      "source": [
        "## Text Pre-Processing\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=18NPGiY9qskAusVD-hzQQ0Lz2uZ8nRyiX' width='500px' />\n",
        "\n",
        "<figcaption>Image Caption</figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itmQv06jbAbF"
      },
      "source": [
        "## CBOW (continuous Bag of Words)\n",
        "\n",
        "**CBOW** predicts words from the surrounding context words; it treats one context as one independent observation.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1L7Ol7refO3mMo92dTytS4CShUfPnsmCB' width='250px' />\n",
        "\n",
        "\n",
        "\n",
        "The CBOW model architecture (Source: https://arxiv.org/pdf/1301.3781.pdf Mikolov el al.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xziwtKthToWe"
      },
      "source": [
        "## Global Vectors for Word Representations (GloVe)\n",
        "\n",
        "Example for using the vector words:  <font color='red'>monarch - man = queen.</font>\n",
        "\n",
        "The main idea is that we can do more than just counting occurences but rather represent the words from the vocabulary of a language as vectors whose entries are real numbers. As such, the GloVe algorithm is analysing word *co-occurrencies* within a text corpus; the steps are as follows:\n",
        "\n",
        "1.   A *co-occurence* matrix $X$ is created where its entries $X_{ij}$ represent how often word $i$ is present in the context of the word $j$. Thus there is a parsing of the corpus for building the matrix $X$ and then the model is constructed based on this matrix.\n",
        "2.   For the words $i$ and $j$ we create vectors $\\vec{w}_i$ and $\\vec{w}_j$ such that $$\\vec{w}_i^T\\cdot\\vec{w}_j+b_i+b_j=\\log (X_{ij})$$ where $b_i$ and $b_j$ are scalar *bias* terms (such as the *y-intercepts* for a linear regression model). We want to build word vectors that retain useful information of how words $i$ and $j$ co-occur.\n",
        "3.   In order to determine the entries for the *word vectors* $\\vec{w}_i$, we minimize the following objective function $$J:=\\sum_{i=1}^{V}\\sum_{j=1}^{V}f(X_{ij}) \\left(\\vec{w}_i^T\\cdot\\vec{w}_j+b_i+b_j-\\log (X_{ij})\\right)^2$$\n",
        "4.   The function $f$ is chosen in order to prevent the skewing of the objective function by the words that co-occur too often. In this sense a choice for the function $f$ could be $$f(X_{ij}):=\\begin{cases}\n",
        "\\left(\\frac{X_{ij}}{x_{max}}\\right)^{\\alpha} \\text{if} \\;\\; X_{ij}<x_{max} \\\\\n",
        "1 \\;\\;\\; \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$ where $\\alpha$ and $x_{max}$ can be adjusted by the user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBbcPwVKYdCP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f23b763-3768-4e99-f194-e591cab7df5c"
      },
      "source": [
        "!pip install glove_python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove_python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/79/7e7e548dd9dcb741935d031117f4bed133276c2a047aadad42f1552d1771/glove_python-0.1.0.tar.gz (263kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.4.1)\n",
            "Building wheels for collected packages: glove-python\n",
            "  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=702608 sha256=41195f4de2cd2bc40180cd60256c0873effc3939008d9b96d1399325387f0da3\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/4b/6d/10c0d2ad32c9d9d68beec9694a6f0b6e83ab1662a90a089a4b\n",
            "Successfully built glove-python\n",
            "Installing collected packages: glove-python\n",
            "Successfully installed glove-python-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjH7krEaYeTs"
      },
      "source": [
        "from glove import Corpus, Glove"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0wjTZ8Yhah"
      },
      "source": [
        "text = [['Hello', 'this','presentation', 'on', 'how','convert' ,'word','number','format'],\n",
        "        ['this' ,'beautiful', 'day'],['Daniel','will','going' , 'office','today'],\n",
        "        ['Want', 'also','introduce','Colab','good','tool','convert','word','number']]\n",
        "# text = \"The chocolate is delicious but it may not be always good for you. Homemade chocolate is fun to make. There are many recipes online.\"\n",
        "# creating a corpus object\n",
        "corpus = Corpus() \n",
        "#training the corpus to generate the co occurence matrix which is used in GloVe\n",
        "corpus.fit(text, window=10)\n",
        "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
        "#We can set the learning rate as it uses Gradient Descent and number of components\n",
        "glove = Glove(no_components=5, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=50, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGUr23D3Yql0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acb3658-f07a-4608-a79c-3f9d72966aac"
      },
      "source": [
        "glove.most_similar('Hello')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('format', 0.9377103562998411),\n",
              " ('number', 0.794133910513137),\n",
              " ('Daniel', 0.6019566689918101),\n",
              " ('convert', 0.4698554931090687)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Oqt4v-Ytz2"
      },
      "source": [
        "print(corpus.matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYin__qSZK0G"
      },
      "source": [
        "## GloVe Application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1fK_16oZMEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c82c74-fa72-4c97-d49b-7634446b3517"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pprint\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAxpLzlGZSLr"
      },
      "source": [
        "text = open(\"drive/My Drive/Colab Notebooks/Christmas_Carol.txt\").read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuzQcGtxZYGk"
      },
      "source": [
        "dataset = nltk.sent_tokenize(text) \n",
        "for i in range(len(dataset)): \n",
        "    dataset[i] = dataset[i].lower() \n",
        "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) \n",
        "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68TcQiv2ZbC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c59979e-4a18-4577-d1b5-4eff37ea303a"
      },
      "source": [
        "dataset[200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' you ll want all day to morrow i suppose '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjjakfYQZgbW"
      },
      "source": [
        "def InfoExtract(document):\n",
        "    sentences = nltk.sent_tokenize(document)\n",
        "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "    sentences = [nltk.pos_tag(sent) for sent in sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRoXD9MEZlGf"
      },
      "source": [
        "InfoExtract(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKT81feLZnyT"
      },
      "source": [
        "sentences = [nltk.word_tokenize(sent) for sent in dataset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFJNNSz-toTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37daf1fd-b3ca-49c2-debb-11152e233aee"
      },
      "source": [
        "sentences[327]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scrooge',\n",
              " 'fell',\n",
              " 'upon',\n",
              " 'his',\n",
              " 'knees',\n",
              " 'and',\n",
              " 'clasped',\n",
              " 'his',\n",
              " 'hands',\n",
              " 'before',\n",
              " 'his',\n",
              " 'face']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMtjt4MFZvPo"
      },
      "source": [
        "### Here we apply the GloVe algorithm to create word vectors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5kwHOjOZwlH"
      },
      "source": [
        "corpus = Corpus() \n",
        "corpus.fit(sentences, window=12)\n",
        "#creating a Glove object which will use the matrix created in the above lines to create embeddings\n",
        "#We can set the learning rate as it uses Gradient Descent and number of components\n",
        "glove = Glove(no_components=10, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=1000, no_threads=20, verbose=False)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwNjQfBuZ6mX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ae2ff3-0cf6-4efe-bc3b-1fc00d41732b"
      },
      "source": [
        "corpus.matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4262x4262 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 122623 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzRkzXmuZ9c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc657da8-d646-4e14-caf9-25c695332208"
      },
      "source": [
        "glove.most_similar('christmas')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('day', 0.9185604412013397),\n",
              " ('merry', 0.9156450891535083),\n",
              " ('business', 0.90382657617194),\n",
              " ('sends', 0.861967957395055)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfGwxhjpSyr1"
      },
      "source": [
        "## Word2Vec\n",
        "\n",
        "It is a combination of models for representing the contextual distribution of words in a corpus.\n",
        "\n",
        "Playground: http://projector.tensorflow.org/\n",
        "\n",
        "There are two main algorithms: **CBOW** (Continuous Bag of Words) and **Skip-Gram**.\n",
        "\n",
        "**CBOW** predicts words from the surrounding context words; it treats one context as one independent observation.\n",
        "\n",
        "**Skip-Gram** predicts the surrounding context words from the target words (in a sense it is the \"inverse\" of CBOW)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knn7tRDWN6Y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eccd583-49a2-4a1a-e441-0ea0367e7add"
      },
      "source": [
        "# importing all necessary modules \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "import warnings \n",
        "  \n",
        "warnings.filterwarnings(action = 'ignore') \n",
        "  \n",
        "import gensim \n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAPDUr83RT4d"
      },
      "source": [
        "### Test Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZFZLWdsRQ85"
      },
      "source": [
        "#  Reads text file \n",
        "sample = text\n",
        "  \n",
        "# Replaces escape character with space \n",
        "#f = s.replace(\"\\n\", \" \") \n",
        "\n",
        "f = text\n",
        "  \n",
        "data = [] \n",
        "  \n",
        "# iterate through each sentence in the file \n",
        "for i in sent_tokenize(f): \n",
        "    temp = [] \n",
        "      \n",
        "    # tokenize the sentence into words \n",
        "    for j in word_tokenize(i): \n",
        "        temp.append(j.lower()) \n",
        "  \n",
        "    data.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ImJQxywaVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ec43f5-55b0-4f8e-f00d-859356cf5449"
      },
      "source": [
        "data[234]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'closed', 'it', 'with', 'a', 'bang', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxLhQMZ5Rlor"
      },
      "source": [
        "### CBOW Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupccuG9Rl56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bbc7b97-fba3-4a50-f7f4-1e9552328b1a"
      },
      "source": [
        "# Create CBOW model \n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1,  \n",
        "                              size = 50, window = 9,sg=0) \n",
        "# Print results \n",
        "print(\"Cosine similarity between 'candle' \" + \n",
        "               \"and 'christmas' - CBOW : \", \n",
        "    model1.similarity('candle', 'christmas')) \n",
        "      \n",
        "print(\"Cosine similarity between 'scrooge' \" +\n",
        "                 \"and 'christmas' - CBOW : \", \n",
        "      model1.similarity('scrooge', 'christmas')) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'candle' and 'christmas' - CBOW :  0.98483485\n",
            "Cosine similarity between 'scrooge' and 'christmas' - CBOW :  0.99985504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a6MmGBPR4N4"
      },
      "source": [
        "### Skip-Gram Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXuf8lYER4la",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78c77cb-abcf-4d08-a68c-11a52c07fd2a"
      },
      "source": [
        "# Create Skip Gram model \n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 50, \n",
        "                                             window = 9, sg = 1) \n",
        "  \n",
        "# Print results \n",
        "print(\"Cosine similarity between 'ghost' \" + \n",
        "               \"and 'christmas' - Skip-Gram : \", \n",
        "    model2.similarity('ghost', 'christmas')) \n",
        "      \n",
        "print(\"Cosine similarity between 'scrooge' \" +\n",
        "                 \"and 'christmas' - Skip-Gram : \", \n",
        "      model2.similarity('scrooge', 'christmas')) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'ghost' and 'christmas' - Skip-Gram :  0.99325514\n",
            "Cosine similarity between 'scrooge' and 'christmas' - Skip-Gram :  0.9892585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WqlfOlVSK_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10547908-2a94-47f1-d159-113dd1bd83d2"
      },
      "source": [
        "model1.wv.most_similar(positive='ghost')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('with', 0.9999064803123474),\n",
              " ('on', 0.9999052286148071),\n",
              " ('an', 0.9999028444290161),\n",
              " ('in', 0.9999011158943176),\n",
              " ('there', 0.9998980760574341),\n",
              " (',', 0.9998955726623535),\n",
              " (\"'s\", 0.9998926520347595),\n",
              " ('we', 0.9998918771743774),\n",
              " ('and', 0.9998918771743774),\n",
              " ('by', 0.9998900890350342)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}