{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "provenance": [],
      "mount_file_id": "18bUp0XcipBedSbMzmZ5_Hf1h-4vjJd4Q",
      "authorship_tag": "ABX9TyOoEa1LgU5JMg0zcgF7vhUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skrofman/Applied-Machine-Learning/blob/master/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-GwrDjOzI4v"
      },
      "source": [
        "**Q1: A stopword is...:**\n",
        "\n",
        "A word that is removed from the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkBw2LkYzOeO"
      },
      "source": [
        "**Q2: Check each of the processes you undertake before entering a text value into your corpus.**\n",
        "\n",
        "*   Remove any extra characters or words that are not informative.\n",
        "*   Convert each word to it's root.\n",
        "*   Ensure all words are lower or upper case in the same way.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHyiIOijzN9W"
      },
      "source": [
        "**Q3: In order to remove any characters that are not lowercase, uppercase, numeric (0 to 9) or spaces, what is the correct line of regex code for the below example (in Python)? X = \"The answer to this question is a secret.\"**\n",
        "\n",
        "re.sub('[^a-zA-Z0-9 ]', '', X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrATKdLF0K0x"
      },
      "source": [
        "**Q4: NLP can be used for both probabilistic (soft) and discrete (hard) classification problems.**\n",
        "\n",
        "False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vuve1zD0XQa"
      },
      "source": [
        "**Q5: Which of the below is not a step unique to pre-processing text data?**\n",
        "\n",
        "Imputation of any missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnyUsm4-0e_0"
      },
      "source": [
        "**Q6: NLP can leverage the same classification algorithms used in other machine learning contexts.**\n",
        "\n",
        "True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nUwOlgU0kDR"
      },
      "source": [
        "**Q7: For all the remaining questions we use the winemagdata130kv2 dataset and we ramdonly subset 7000 reviews with a random state = 310.  If we plot a histogram of the target variable do we see that the distribution is almost normal ?**\n",
        "\n",
        "True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0mzmdGTqekU",
        "outputId": "e160c57a-6bb5-44be-cb1a-0384864265d9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVbJxvayvALp"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.metrics import accuracy_score as acc\n",
        "import heapq \n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt3E2ynQqd_J",
        "outputId": "1a2eb4d2-7952-4d29-aba4-be909c65f5c7"
      },
      "source": [
        "%%time\n",
        "wine_data = pd.read_csv('/content/drive/MyDrive/winemagdata130kv2.csv',quoting=2)\n",
        "wines = wine_data[[\"description\",\"points\"]]\n",
        "wines_subset = wines.sample(7000,random_state=310).reset_index(drop=True)\n",
        "corpus = []\n",
        "\n",
        "for i in range(0,len(wines_subset)):\n",
        "    wine_descriptions = re.sub('[^a-zA-Z0-9 ]','',wines_subset[\"description\"][i])\n",
        "    wine_descriptions=wine_descriptions.lower()\n",
        "    wine_descriptions = wine_descriptions.split()\n",
        "    wine_descriptions = [word for word in wine_descriptions if not word in set(stopwords.words('english'))]\n",
        "    stemmer = PorterStemmer()\n",
        "    wine_descriptions = [stemmer.stem(word) for word in wine_descriptions]\n",
        "    wine_descriptions = \" \".join(wine_descriptions)\n",
        "    corpus.append(wine_descriptions)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 37.2 s, sys: 3.33 s, total: 40.6 s\n",
            "Wall time: 40.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpqHeG9GwcOI",
        "outputId": "54aa995b-130a-441a-89cd-f5189face84f"
      },
      "source": [
        "%%time\n",
        "countVec = CountVectorizer()\n",
        "X_raw = countVec.fit_transform(corpus)\n",
        "X = X_raw.toarray()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 239 ms, sys: 72.2 ms, total: 312 ms\n",
            "Wall time: 315 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GiDrD66Owdhw",
        "outputId": "5b7c6986-c2e6-4627-8bdc-368cc6a774dd"
      },
      "source": [
        "#### Visualize the distribution of the wine ratings (points)\n",
        "n, bins, patches = plt.hist(wines_subset[\"points\"].values,10,density=1,facecolor='green',alpha=0.7)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFF1Mwcv0q1-"
      },
      "source": [
        "**Q8: For all the remaining questions we use the winemagdata130kv2 dataset and we ramdonly subset 7000 reviews with a random state = 310 and we preprocess in the sense of Natural Language Processing (as explained in class) all the customer reviews. We label as Good those wines who had more than 90 points (in the target variable). We subset the data into Train and Test sets such that the Test set is about 25% and we train a logistic regression classifier. When this model is applied to the Test set we see that the number of  Good correctly classified as Good is**\n",
        "\n",
        "261"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5icwu9Xw9L9"
      },
      "source": [
        "y = wines_subset[\"points\"]\n",
        "y = y.where(y>90,other=0).where(y<=90,other=1).values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHg_tt1-w9cQ"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = tts(X,y,random_state=310, test_size=0.25)\n",
        "#scale_X = StandardScaler()\n",
        "#X_train = scale_X.fit_transform(X_train)\n",
        "#X_test = scale_X.transform(X_test)\n",
        "classifier = LogisticRegression(random_state=310, solver='lbfgs')\n",
        "classifier.fit(X_train,Y_train)\n",
        "Y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "5CmHinuDxJn6",
        "outputId": "ebae3f3e-25c3-4c62-9e24-64d4d8661cfd"
      },
      "source": [
        "spc = ['Bad','Good']\n",
        "cm = confusion_matrix(Y_test,Y_pred)\n",
        "pd.DataFrame(cm, columns=spc, index=spc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bad</th>\n",
              "      <th>Good</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bad</th>\n",
              "      <td>1206</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>186</td>\n",
              "      <td>261</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Bad  Good\n",
              "Bad   1206    97\n",
              "Good   186   261"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IleNnne050S"
      },
      "source": [
        "**Q9: The overall accuracy for applying the logistic regression classifier on the Test set is (as a percetage with 2 decimals, eg.format like 53.74 without rounding):**\n",
        "\n",
        "0.8382857142857143"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9p_8C1txM4f",
        "outputId": "bb6f2bf7-d85c-45dd-b463-2f55aabac3d3"
      },
      "source": [
        "acc(Y_test,Y_pred)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8382857142857143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPuD7DXixYdZ"
      },
      "source": [
        "#X_train, X_test, Y_train, Y_test = tts(X,y,test_size=0.25)\n",
        "cls = RandomForestClassifier(max_depth=150, n_estimators = 500, random_state=310)\n",
        "cls.fit(X_train,Y_train)\n",
        "Y_pred = cls.predict(X_test)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIwghJqX1kZb"
      },
      "source": [
        "**Q10: If we train a random forest classifier with 500 trees and a max_depth of 150 then the number of not good winse classified correctly as not good is**\n",
        "\n",
        "1303"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "wn7lOGESyCXA",
        "outputId": "9de64e47-8886-42fe-9b04-c88dbe3d0b6a"
      },
      "source": [
        "spc = ['Bad','Good']\n",
        "cm = confusion_matrix(Y_test,Y_pred)\n",
        "pd.DataFrame(cm, columns=spc, index=spc)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bad</th>\n",
              "      <th>Good</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bad</th>\n",
              "      <td>1303</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Good</th>\n",
              "      <td>406</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Bad  Good\n",
              "Bad   1303     0\n",
              "Good   406    41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VUqq2a1zOjU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}